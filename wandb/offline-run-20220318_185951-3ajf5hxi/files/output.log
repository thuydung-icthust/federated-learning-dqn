>>> START RUNNING: FedAVG-Equal-Non-IID-01-2.1.1 - Train mode: benchmark - Dataset: chexpert
START LOADING CHEXPERT DATASET...
Init State dim 6
Init Action dim 3
ROUND:  0
[5, 5, 5]
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
label[0] : 0
label shape: 14
torch.FloatTensor(label[0]): tensor([])
output: tensor([[-0.7053,  0.0078],
        [-1.0265, -0.2519],
        [-0.7252,  0.0719],
        [-0.4770, -0.0181],
        [-0.9283, -0.1329],
        [-0.7998, -0.0812],
        [-0.7533,  0.0389],
        [-0.8300, -0.1297],
        [-0.7861, -0.0066],
        [-1.0433, -0.1944]], device='cuda:0', grad_fn=<AddmmBackward0>)
x: tensor([[[[-0.4568, -0.4911, -0.5424,  ..., -1.9638, -1.9638, -1.9467],
          [-0.5082, -0.5938, -0.6452,  ..., -1.9467, -1.9467, -1.9467],
          [-0.6794, -0.6109, -0.5938,  ..., -1.9295, -1.9295, -1.9467],
          ...,
          [ 0.7933,  0.8104,  0.7419,  ...,  0.6392,  0.6049,  0.5193],
          [ 0.8104,  0.8104,  0.7762,  ...,  0.6221,  0.5536,  0.4679],
          [ 0.6906,  0.6563,  0.7591,  ...,  0.7419,  0.6734,  0.6392]],
         [[-0.3375, -0.3725, -0.4251,  ..., -1.8782, -1.8782, -1.8606],
          [-0.3901, -0.4776, -0.5301,  ..., -1.8606, -1.8606, -1.8606],
          [-0.5651, -0.4951, -0.4776,  ..., -1.8431, -1.8431, -1.8606],
          ...,
          [ 0.9405,  0.9580,  0.8880,  ...,  0.7829,  0.7479,  0.6604],
          [ 0.9580,  0.9580,  0.9230,  ...,  0.7654,  0.6954,  0.6078],
          [ 0.8354,  0.8004,  0.9055,  ...,  0.8880,  0.8179,  0.7829]],
         [[-0.1138, -0.1487, -0.2010,  ..., -1.6476, -1.6476, -1.6302],
          [-0.1661, -0.2532, -0.3055,  ..., -1.6302, -1.6302, -1.6302],
          [-0.3404, -0.2707, -0.2532,  ..., -1.6127, -1.6127, -1.6302],
          ...,
          [ 1.1585,  1.1759,  1.1062,  ...,  1.0017,  0.9668,  0.8797],
          [ 1.1759,  1.1759,  1.1411,  ...,  0.9842,  0.9145,  0.8274],
          [ 1.0539,  1.0191,  1.1237,  ...,  1.1062,  1.0365,  1.0017]]],
        [[[ 0.1426,  0.1426,  0.1426,  ..., -2.0494, -2.0494, -2.0323],
          [ 0.1426,  0.1254,  0.1426,  ..., -2.0494, -2.0665, -2.0494],
          [ 0.1597,  0.1254,  0.1426,  ..., -2.0837, -2.0494, -2.0494],
          ...,
          [-0.0972, -0.0116, -0.0458,  ...,  1.4269,  1.3927,  1.4954],
          [ 0.0398,  0.0056,  0.0227,  ...,  1.4612,  1.4783,  1.5297],
          [-0.0116, -0.0458, -0.0801,  ...,  1.5297,  1.4783,  1.4269]],
         [[ 0.2752,  0.2752,  0.2752,  ..., -1.9657, -1.9657, -1.9482],
          [ 0.2752,  0.2577,  0.2752,  ..., -1.9657, -1.9832, -1.9657],
          [ 0.2927,  0.2577,  0.2752,  ..., -2.0007, -1.9657, -1.9657],
          ...,
          [ 0.0301,  0.1176,  0.0826,  ...,  1.5882,  1.5532,  1.6583],
          [ 0.1702,  0.1352,  0.1527,  ...,  1.6232,  1.6408,  1.6933],
          [ 0.1176,  0.0826,  0.0476,  ...,  1.6933,  1.6408,  1.5882]],
         [[ 0.4962,  0.4962,  0.4962,  ..., -1.7347, -1.7347, -1.7173],
          [ 0.4962,  0.4788,  0.4962,  ..., -1.7347, -1.7522, -1.7347],
          [ 0.5136,  0.4788,  0.4962,  ..., -1.7696, -1.7347, -1.7347],
          ...,
          [ 0.2522,  0.3393,  0.3045,  ...,  1.8034,  1.7685,  1.8731],
          [ 0.3916,  0.3568,  0.3742,  ...,  1.8383,  1.8557,  1.9080],
          [ 0.3393,  0.3045,  0.2696,  ...,  1.9080,  1.8557,  1.8034]]],
        [[[-0.0801,  1.5982, -0.4226,  ..., -0.3712, -0.6281, -0.6452],
          [ 1.6153,  1.0502, -0.0801,  ..., -0.6452, -0.6281, -0.4568],
          [ 0.8104, -0.1314, -0.2684,  ..., -0.5596, -0.2856, -0.4397],
          ...,
          [ 0.2624,  0.2624,  0.3481,  ..., -1.9124, -2.0837, -2.0152],
          [ 0.2111,  0.1939,  0.3138,  ..., -1.9467, -2.0837, -2.0323],
          [ 0.2624,  0.3994,  0.3481,  ..., -1.9124, -2.0837, -2.0323]],
         [[ 0.0476,  1.7633, -0.3025,  ..., -0.2500, -0.5126, -0.5301],
          [ 1.7808,  1.2031,  0.0476,  ..., -0.5301, -0.5126, -0.3375],
          [ 0.9580, -0.0049, -0.1450,  ..., -0.4426, -0.1625, -0.3200],
          ...,
          [ 0.3978,  0.3978,  0.4853,  ..., -1.8256, -2.0007, -1.9307],
          [ 0.3452,  0.3277,  0.4503,  ..., -1.8606, -2.0007, -1.9482],
          [ 0.3978,  0.5378,  0.4853,  ..., -1.8256, -2.0007, -1.9482]],
         [[ 0.2696,  1.9777, -0.0790,  ..., -0.0267, -0.2881, -0.3055],
          [ 1.9951,  1.4200,  0.2696,  ..., -0.3055, -0.2881, -0.1138],
          [ 1.1759,  0.2173,  0.0779,  ..., -0.2184,  0.0605, -0.0964],
          ...,
          [ 0.6182,  0.6182,  0.7054,  ..., -1.5953, -1.7696, -1.6999],
          [ 0.5659,  0.5485,  0.6705,  ..., -1.6302, -1.7696, -1.7173],
          [ 0.6182,  0.7576,  0.7054,  ..., -1.5953, -1.7696, -1.7173]]],
        ...,
        [[[-0.2342, -0.0801, -0.3712,  ..., -0.4568, -1.5185, -1.8268],
          [-0.0972, -0.0287, -0.2171,  ..., -0.9705, -0.8849, -1.2959],
          [-0.5082, -0.4054, -0.3712,  ..., -0.2171,  0.4337,  0.3652],
          ...,
          [ 2.2147,  2.2147,  2.2318,  ..., -1.7754, -1.7240, -1.4500],
          [ 2.1975,  2.1975,  2.2147,  ..., -1.7925, -1.8268, -1.5699],
          [ 2.1975,  2.1975,  2.1975,  ..., -1.7754, -1.7925, -1.4843]],
         [[-0.1099,  0.0476, -0.2500,  ..., -0.3375, -1.4230, -1.7381],
          [ 0.0301,  0.1001, -0.0924,  ..., -0.8627, -0.7752, -1.1954],
          [-0.3901, -0.2850, -0.2500,  ..., -0.0924,  0.5728,  0.5028],
          ...,
          [ 2.3936,  2.3936,  2.4111,  ..., -1.6856, -1.6331, -1.3529],
          [ 2.3761,  2.3761,  2.3936,  ..., -1.7031, -1.7381, -1.4755],
          [ 2.3761,  2.3761,  2.3761,  ..., -1.6856, -1.7031, -1.3880]],
         [[ 0.1128,  0.2696, -0.0267,  ..., -0.1138, -1.1944, -1.5081],
          [ 0.2522,  0.3219,  0.1302,  ..., -0.6367, -0.5495, -0.9678],
          [-0.1661, -0.0615, -0.0267,  ...,  0.1302,  0.7925,  0.7228],
          ...,
          [ 2.6051,  2.6051,  2.6226,  ..., -1.4559, -1.4036, -1.1247],
          [ 2.5877,  2.5877,  2.6051,  ..., -1.4733, -1.5081, -1.2467],
          [ 2.5877,  2.5877,  2.5877,  ..., -1.4559, -1.4733, -1.1596]]],
        [[[-0.2856, -0.2513, -0.3541,  ..., -0.7479, -0.6794, -0.8507],
          [ 0.1768,  0.0569, -0.1999,  ..., -0.5938, -0.6109, -0.7993],
          [-0.4568, -0.2856, -0.1999,  ..., -0.6623, -0.5767, -0.8507],
          ...,
          [ 0.6734,  0.6392,  0.6392,  ...,  1.6495,  1.7009,  1.5468],
          [ 0.6049,  0.5707,  0.5707,  ...,  1.7180,  1.5639,  1.6838],
          [ 0.6392,  0.6906,  0.7077,  ...,  1.5639,  1.5468,  1.5468]],
         [[-0.1625, -0.1275, -0.2325,  ..., -0.6352, -0.5651, -0.7402],
          [ 0.3102,  0.1877, -0.0749,  ..., -0.4776, -0.4951, -0.6877],
          [-0.3375, -0.1625, -0.0749,  ..., -0.5476, -0.4601, -0.7402],
          ...,
          [ 0.8179,  0.7829,  0.7829,  ...,  1.8158,  1.8683,  1.7108],
          [ 0.7479,  0.7129,  0.7129,  ...,  1.8859,  1.7283,  1.8508],
          [ 0.7829,  0.8354,  0.8529,  ...,  1.7283,  1.7108,  1.7108]],
         [[ 0.0605,  0.0953, -0.0092,  ..., -0.4101, -0.3404, -0.5147],
          [ 0.5311,  0.4091,  0.1476,  ..., -0.2532, -0.2707, -0.4624],
          [-0.1138,  0.0605,  0.1476,  ..., -0.3230, -0.2358, -0.5147],
          ...,
          [ 1.0365,  1.0017,  1.0017,  ...,  2.0300,  2.0823,  1.9254],
          [ 0.9668,  0.9319,  0.9319,  ...,  2.0997,  1.9428,  2.0648],
          [ 1.0017,  1.0539,  1.0714,  ...,  1.9428,  1.9254,  1.9254]]],
        [[[-0.5082, -0.4054, -0.7308,  ..., -2.1008, -2.0837, -2.0837],
          [-0.6109, -0.4911, -0.5082,  ..., -2.1008, -2.0837, -2.1008],
          [-0.9020, -0.8507, -0.8164,  ..., -2.1008, -2.0837, -2.1008],
          ...,
          [ 1.4783,  1.4783,  1.5125,  ...,  0.3138,  0.1254, -0.1486],
          [ 1.4098,  1.6667,  1.6153,  ...,  0.2967,  0.0912, -0.1486],
          [ 1.6153,  1.6838,  1.5639,  ...,  0.1768,  0.0569, -0.2342]],
         [[-0.3901, -0.2850, -0.6176,  ..., -2.0182, -2.0007, -2.0007],
          [-0.4951, -0.3725, -0.3901,  ..., -2.0182, -2.0007, -2.0182],
          [-0.7927, -0.7402, -0.7052,  ..., -2.0182, -2.0007, -2.0182],
          ...,
          [ 1.6408,  1.6408,  1.6758,  ...,  0.4503,  0.2577, -0.0224],
          [ 1.5707,  1.8333,  1.7808,  ...,  0.4328,  0.2227, -0.0224],
          [ 1.7808,  1.8508,  1.7283,  ...,  0.3102,  0.1877, -0.1099]],
         [[-0.1661, -0.0615, -0.3927,  ..., -1.7870, -1.7696, -1.7696],
          [-0.2707, -0.1487, -0.1661,  ..., -1.7870, -1.7696, -1.7870],
          [-0.5670, -0.5147, -0.4798,  ..., -1.7870, -1.7696, -1.7870],
          ...,
          [ 1.8557,  1.8557,  1.8905,  ...,  0.6705,  0.4788,  0.1999],
          [ 1.7860,  2.0474,  1.9951,  ...,  0.6531,  0.4439,  0.1999],
          [ 1.9951,  2.0648,  1.9428,  ...,  0.5311,  0.4091,  0.1128]]]],
       device='cuda:0')
y: tensor([], device='cuda:0', size=(10, 0))
output: tensor([[-1.0474e+00, -9.4987e-04],
        [-6.3551e-01, -5.2065e-02],
        [-6.9254e-01, -4.6451e-02],
        [-1.0596e+00, -1.7996e-01],
        [-7.6627e-01, -5.6550e-02],
        [-7.6104e-01,  2.1752e-02],
        [-6.2918e-01,  1.1501e-03],
        [-1.0023e+00, -1.0853e-01],
        [-8.7495e-01, -3.1467e-02],
        [-7.4984e-01, -9.0178e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)
x: tensor([[[[-1.8097, -1.8097, -1.6384,  ..., -1.6384, -1.7240, -1.8610],
          [-1.7240, -1.7069, -1.6213,  ..., -1.6042, -1.7240, -1.8268],
          [-1.6555, -1.8097, -1.5014,  ..., -1.6042, -1.7240, -1.6555],
          ...,
          [-1.9124, -1.7754, -1.8782,  ..., -1.5185, -1.5528, -1.3644],
          [-1.8610, -1.7583, -1.8097,  ..., -1.5185, -1.5699, -1.3815],
          [-1.8953, -1.7583, -1.8097,  ..., -1.5699, -1.4329, -1.3644]],
         [[-1.7206, -1.7206, -1.5455,  ..., -1.5455, -1.6331, -1.7731],
          [-1.6331, -1.6155, -1.5280,  ..., -1.5105, -1.6331, -1.7381],
          [-1.5630, -1.7206, -1.4055,  ..., -1.5105, -1.6331, -1.5630],
          ...,
          [-1.8256, -1.6856, -1.7906,  ..., -1.4230, -1.4580, -1.2654],
          [-1.7731, -1.6681, -1.7206,  ..., -1.4230, -1.4755, -1.2829],
          [-1.8081, -1.6681, -1.7206,  ..., -1.4755, -1.3354, -1.2654]],
         [[-1.4907, -1.4907, -1.3164,  ..., -1.3164, -1.4036, -1.5430],
          [-1.4036, -1.3861, -1.2990,  ..., -1.2816, -1.4036, -1.5081],
          [-1.3339, -1.4907, -1.1770,  ..., -1.2816, -1.4036, -1.3339],
          ...,
          [-1.5953, -1.4559, -1.5604,  ..., -1.1944, -1.2293, -1.0376],
          [-1.5430, -1.4384, -1.4907,  ..., -1.1944, -1.2467, -1.0550],
          [-1.5779, -1.4384, -1.4907,  ..., -1.2467, -1.1073, -1.0376]]],
        [[[-0.4397, -0.4568, -0.5253,  ...,  0.8789,  0.8447,  0.8447],
          [-0.4739, -0.4739, -0.5082,  ...,  0.9646,  0.9132,  0.9132],
          [-0.5424, -0.5253, -0.4568,  ...,  1.0844,  1.0159,  1.0159],
          ...,
          [ 1.9407,  1.9235,  1.8550,  ...,  2.1975,  2.2147,  2.2147],
          [ 1.9235,  1.9064,  1.8550,  ...,  2.2147,  2.2147,  2.2147],
          [ 1.9064,  1.8893,  1.8550,  ...,  2.2147,  2.2147,  2.2147]],
         [[-0.3200, -0.3375, -0.4076,  ...,  1.0280,  0.9930,  0.9930],
          [-0.3550, -0.3550, -0.3901,  ...,  1.1155,  1.0630,  1.0630],
          [-0.4251, -0.4076, -0.3375,  ...,  1.2381,  1.1681,  1.1681],
          ...,
          [ 2.1134,  2.0959,  2.0259,  ...,  2.3761,  2.3936,  2.3936],
          [ 2.0959,  2.0784,  2.0259,  ...,  2.3936,  2.3936,  2.3936],
          [ 2.0784,  2.0609,  2.0259,  ...,  2.3936,  2.3936,  2.3936]],
         [[-0.0964, -0.1138, -0.1835,  ...,  1.2457,  1.2108,  1.2108],
          [-0.1312, -0.1312, -0.1661,  ...,  1.3328,  1.2805,  1.2805],
          [-0.2010, -0.1835, -0.1138,  ...,  1.4548,  1.3851,  1.3851],
          ...,
          [ 2.3263,  2.3088,  2.2391,  ...,  2.5877,  2.6051,  2.6051],
          [ 2.3088,  2.2914,  2.2391,  ...,  2.6051,  2.6051,  2.6051],
          [ 2.2914,  2.2740,  2.2391,  ...,  2.6051,  2.6051,  2.6051]]],
        [[[ 0.4337,  0.4337,  0.4166,  ..., -0.3027, -0.3369, -0.3541],
          [ 0.5022,  0.5022,  0.4851,  ..., -0.3712, -0.3712, -0.3712],
          [ 0.5364,  0.5022,  0.4851,  ..., -0.4397, -0.3541, -0.3027],
          ...,
          [ 2.1633,  2.1462,  2.1290,  ...,  1.8550,  1.7694,  1.7009],
          [ 2.1633,  2.1462,  2.1290,  ...,  1.8893,  1.7352,  1.6153],
          [ 2.1462,  2.1290,  2.1119,  ...,  1.8379,  1.6838,  1.5639]],
         [[ 0.5728,  0.5728,  0.5553,  ..., -0.1800, -0.2150, -0.2325],
          [ 0.6429,  0.6429,  0.6254,  ..., -0.2500, -0.2500, -0.2500],
          [ 0.6779,  0.6429,  0.6254,  ..., -0.3200, -0.2325, -0.1800],
          ...,
          [ 2.3410,  2.3235,  2.3060,  ...,  2.0259,  1.9384,  1.8683],
          [ 2.3410,  2.3235,  2.3060,  ...,  2.0609,  1.9034,  1.7808],
          [ 2.3235,  2.3060,  2.2885,  ...,  2.0084,  1.8508,  1.7283]],
         [[ 0.7925,  0.7925,  0.7751,  ...,  0.0431,  0.0082, -0.0092],
          [ 0.8622,  0.8622,  0.8448,  ..., -0.0267, -0.0267, -0.0267],
          [ 0.8971,  0.8622,  0.8448,  ..., -0.0964, -0.0092,  0.0431],
          ...,
          [ 2.5529,  2.5354,  2.5180,  ...,  2.2391,  2.1520,  2.0823],
          [ 2.5529,  2.5354,  2.5180,  ...,  2.2740,  2.1171,  1.9951],
          [ 2.5354,  2.5180,  2.5006,  ...,  2.2217,  2.0648,  1.9428]]],
        ...,
        [[[-2.1008, -2.0837, -2.0837,  ..., -2.0494, -2.0494, -2.0494],
          [-2.1008, -2.1008, -2.1008,  ..., -2.0665, -2.0665, -2.0665],
          [-2.1008, -2.0837, -2.0494,  ..., -2.0837, -2.0837, -2.0837],
          ...,
          [ 0.9988,  1.0673,  1.0844,  ...,  1.8550,  1.7523,  1.8379],
          [ 0.9646,  1.0331,  1.0673,  ...,  1.8550,  1.7865,  1.7523],
          [ 0.9817,  0.9646,  1.0331,  ...,  1.8208,  1.8550,  1.8208]],
         [[-2.0182, -2.0007, -2.0007,  ..., -1.9657, -1.9657, -1.9657],
          [-2.0182, -2.0182, -2.0182,  ..., -1.9832, -1.9832, -1.9832],
          [-2.0182, -2.0007, -1.9657,  ..., -2.0007, -2.0007, -2.0007],
          ...,
          [ 1.1506,  1.2206,  1.2381,  ...,  2.0259,  1.9209,  2.0084],
          [ 1.1155,  1.1856,  1.2206,  ...,  2.0259,  1.9559,  1.9209],
          [ 1.1331,  1.1155,  1.1856,  ...,  1.9909,  2.0259,  1.9909]],
         [[-1.7870, -1.7696, -1.7696,  ..., -1.7347, -1.7347, -1.7347],
          [-1.7870, -1.7870, -1.7870,  ..., -1.7522, -1.7522, -1.7522],
          [-1.7870, -1.7696, -1.7347,  ..., -1.7696, -1.7696, -1.7696],
          ...,
          [ 1.3677,  1.4374,  1.4548,  ...,  2.2391,  2.1346,  2.2217],
          [ 1.3328,  1.4025,  1.4374,  ...,  2.2391,  2.1694,  2.1346],
          [ 1.3502,  1.3328,  1.4025,  ...,  2.2043,  2.2391,  2.2043]]],
        [[[-0.3198, -0.0458, -0.1828,  ...,  0.3481,  0.4851,  0.1254],
          [-0.1486,  0.1939, -0.1828,  ...,  0.1768,  0.2282,  0.1254],
          [-0.0629, -0.0287,  0.0912,  ...,  0.2624,  0.5364,  0.2111],
          ...,
          [ 1.1015,  1.1700,  1.3070,  ...,  0.2453,  0.0912,  0.0227],
          [ 1.2214,  1.1872,  1.2557,  ...,  0.3138,  0.5022, -0.0287],
          [ 1.1529,  1.1700,  1.2557,  ...,  0.5364,  0.3652,  0.2282]],
         [[-0.1975,  0.0826, -0.0574,  ...,  0.4853,  0.6254,  0.2577],
          [-0.0224,  0.3277, -0.0574,  ...,  0.3102,  0.3627,  0.2577],
          [ 0.0651,  0.1001,  0.2227,  ...,  0.3978,  0.6779,  0.3452],
          ...,
          [ 1.2556,  1.3256,  1.4657,  ...,  0.3803,  0.2227,  0.1527],
          [ 1.3782,  1.3431,  1.4132,  ...,  0.4503,  0.6429,  0.1001],
          [ 1.3081,  1.3256,  1.4132,  ...,  0.6779,  0.5028,  0.3627]],
         [[ 0.0256,  0.3045,  0.1651,  ...,  0.7054,  0.8448,  0.4788],
          [ 0.1999,  0.5485,  0.1651,  ...,  0.5311,  0.5834,  0.4788],
          [ 0.2871,  0.3219,  0.4439,  ...,  0.6182,  0.8971,  0.5659],
          ...,
          [ 1.4722,  1.5420,  1.6814,  ...,  0.6008,  0.4439,  0.3742],
          [ 1.5942,  1.5594,  1.6291,  ...,  0.6705,  0.8622,  0.3219],
          [ 1.5245,  1.5420,  1.6291,  ...,  0.8971,  0.7228,  0.5834]]],
        [[[ 0.3823,  0.5536,  0.6392,  ...,  0.7248,  0.7762,  0.5364],
          [ 0.5536,  0.5707,  0.6392,  ...,  0.7933,  0.8447,  0.8447],
          [ 0.5022,  0.5878,  0.6563,  ...,  0.9132,  0.9303,  0.8618],
          ...,
          [ 0.4508,  0.5193,  0.6221,  ...,  0.8447,  0.9132,  0.9132],
          [ 0.5707,  0.6563,  0.7591,  ...,  0.8104,  0.8789,  0.9474],
          [ 0.6392,  0.6734,  0.8104,  ...,  0.9474,  1.1187,  1.0673]],
         [[ 0.5203,  0.6954,  0.7829,  ...,  0.8704,  0.9230,  0.6779],
          [ 0.6954,  0.7129,  0.7829,  ...,  0.9405,  0.9930,  0.9930],
          [ 0.6429,  0.7304,  0.8004,  ...,  1.0630,  1.0805,  1.0105],
          ...,
          [ 0.5903,  0.6604,  0.7654,  ...,  0.9930,  1.0630,  1.0630],
          [ 0.7129,  0.8004,  0.9055,  ...,  0.9580,  1.0280,  1.0980],
          [ 0.7829,  0.8179,  0.9580,  ...,  1.0980,  1.2731,  1.2206]],
         [[ 0.7402,  0.9145,  1.0017,  ...,  1.0888,  1.1411,  0.8971],
          [ 0.9145,  0.9319,  1.0017,  ...,  1.1585,  1.2108,  1.2108],
          [ 0.8622,  0.9494,  1.0191,  ...,  1.2805,  1.2980,  1.2282],
          ...,
          [ 0.8099,  0.8797,  0.9842,  ...,  1.2108,  1.2805,  1.2805],
          [ 0.9319,  1.0191,  1.1237,  ...,  1.1759,  1.2457,  1.3154],
          [ 1.0017,  1.0365,  1.1759,  ...,  1.3154,  1.4897,  1.4374]]]],
       device='cuda:0')
y: tensor([], device='cuda:0', size=(10, 0))
output: tensor([[-0.7334, -0.0408],
        [-0.6541,  0.0166],
        [-0.6598, -0.0574],
        [-0.7710, -0.0374],
        [-1.1122, -0.1142],
        [-0.8137, -0.1603],
        [-0.7084,  0.0739],
        [-0.5962, -0.0075],
        [-0.9158, -0.1442],
        [-1.0475, -0.2398]], device='cuda:0', grad_fn=<AddmmBackward0>)
x: tensor([[[[-0.2856, -0.4739, -0.3712,  ..., -0.0287, -0.1143, -0.1314],
          [-0.1314, -0.2342, -0.3369,  ..., -0.0287, -0.0972, -0.2171],
          [-0.0458, -0.0801, -0.1143,  ...,  0.1426,  0.0569,  0.0398],
          ...,
          [ 1.8550,  1.7009,  1.6838,  ...,  1.7523,  1.6153,  1.5639],
          [ 1.7865,  1.7694,  1.7352,  ...,  1.7865,  1.6667,  1.4954],
          [ 1.6495,  1.8208,  1.7009,  ...,  1.7352,  1.9578,  1.4954]],
         [[-0.1625, -0.3550, -0.2500,  ...,  0.1001,  0.0126, -0.0049],
          [-0.0049, -0.1099, -0.2150,  ...,  0.1001,  0.0301, -0.0924],
          [ 0.0826,  0.0476,  0.0126,  ...,  0.2752,  0.1877,  0.1702],
          ...,
          [ 2.0259,  1.8683,  1.8508,  ...,  1.9209,  1.7808,  1.7283],
          [ 1.9559,  1.9384,  1.9034,  ...,  1.9559,  1.8333,  1.6583],
          [ 1.8158,  1.9909,  1.8683,  ...,  1.9034,  2.1310,  1.6583]],
         [[ 0.0605, -0.1312, -0.0267,  ...,  0.3219,  0.2348,  0.2173],
          [ 0.2173,  0.1128,  0.0082,  ...,  0.3219,  0.2522,  0.1302],
          [ 0.3045,  0.2696,  0.2348,  ...,  0.4962,  0.4091,  0.3916],
          ...,
          [ 2.2391,  2.0823,  2.0648,  ...,  2.1346,  1.9951,  1.9428],
          [ 2.1694,  2.1520,  2.1171,  ...,  2.1694,  2.0474,  1.8731],
          [ 2.0300,  2.2043,  2.0823,  ...,  2.1171,  2.3437,  1.8731]]],
        [[[-2.0323, -2.0494, -2.0494,  ..., -1.8439, -1.8782, -1.8610],
          [-1.9467, -1.9638, -1.9638,  ..., -1.8610, -1.8439, -1.8610],
          [-1.7925, -1.8268, -1.7925,  ..., -1.8782, -1.9124, -1.8782],
          ...,
          [ 1.4269,  1.5125,  1.5468,  ...,  1.8550,  1.7180,  1.8037],
          [ 1.4269,  1.4612,  1.4954,  ...,  1.8379,  1.6667,  1.7523],
          [ 1.4098,  1.3755,  1.5125,  ...,  2.0092,  1.8208,  1.9578]],
         [[-1.9482, -1.9657, -1.9657,  ..., -1.7556, -1.7906, -1.7731],
          [-1.8606, -1.8782, -1.8782,  ..., -1.7731, -1.7556, -1.7731],
          [-1.7031, -1.7381, -1.7031,  ..., -1.7906, -1.8256, -1.7906],
          ...,
          [ 1.5882,  1.6758,  1.7108,  ...,  2.0259,  1.8859,  1.9734],
          [ 1.5882,  1.6232,  1.6583,  ...,  2.0084,  1.8333,  1.9209],
          [ 1.5707,  1.5357,  1.6758,  ...,  2.1835,  1.9909,  2.1310]],
         [[-1.7173, -1.7347, -1.7347,  ..., -1.5256, -1.5604, -1.5430],
          [-1.6302, -1.6476, -1.6476,  ..., -1.5430, -1.5256, -1.5430],
          [-1.4733, -1.5081, -1.4733,  ..., -1.5604, -1.5953, -1.5604],
          ...,
          [ 1.8034,  1.8905,  1.9254,  ...,  2.2391,  2.0997,  2.1868],
          [ 1.8034,  1.8383,  1.8731,  ...,  2.2217,  2.0474,  2.1346],
          [ 1.7860,  1.7511,  1.8905,  ...,  2.3960,  2.2043,  2.3437]]],
        [[[-0.5424, -0.2856, -0.1828,  ...,  0.0227,  0.0912,  0.1939],
          [-0.6109, -0.3541, -0.1828,  ..., -0.3369, -0.2684, -0.0972],
          [ 0.1254,  0.0056, -0.1314,  ...,  0.0569, -0.0629, -0.2856],
          ...,
          [ 1.4954,  1.5639,  1.6495,  ...,  1.6324,  1.5982,  1.5468],
          [ 1.5639,  1.6667,  1.6667,  ...,  1.5982,  1.6153,  1.6324],
          [ 1.7009,  1.6838,  1.6495,  ...,  1.6153,  1.5810,  1.5810]],
         [[-0.4251, -0.1625, -0.0574,  ...,  0.1527,  0.2227,  0.3277],
          [-0.4951, -0.2325, -0.0574,  ..., -0.2150, -0.1450,  0.0301],
          [ 0.2577,  0.1352, -0.0049,  ...,  0.1877,  0.0651, -0.1625],
          ...,
          [ 1.6583,  1.7283,  1.8158,  ...,  1.7983,  1.7633,  1.7108],
          [ 1.7283,  1.8333,  1.8333,  ...,  1.7633,  1.7808,  1.7983],
          [ 1.8683,  1.8508,  1.8158,  ...,  1.7808,  1.7458,  1.7458]],
         [[-0.2010,  0.0605,  0.1651,  ...,  0.3742,  0.4439,  0.5485],
          [-0.2707, -0.0092,  0.1651,  ...,  0.0082,  0.0779,  0.2522],
          [ 0.4788,  0.3568,  0.2173,  ...,  0.4091,  0.2871,  0.0605],
          ...,
          [ 1.8731,  1.9428,  2.0300,  ...,  2.0125,  1.9777,  1.9254],
          [ 1.9428,  2.0474,  2.0474,  ...,  1.9777,  1.9951,  2.0125],
          [ 2.0823,  2.0648,  2.0300,  ...,  1.9951,  1.9603,  1.9603]]],
        ...,
        [[[-0.5253, -0.5767, -0.7650,  ..., -2.1179, -2.1179, -2.1179],
          [-0.6109, -0.6623, -0.6794,  ..., -2.1179, -2.1179, -2.1179],
          [-0.6965, -0.7479, -0.5938,  ..., -2.1179, -2.1179, -2.1179],
          ...,
          [ 1.5639,  1.4612,  1.3927,  ..., -1.5185, -1.5014, -1.5357],
          [ 1.5639,  1.5125,  1.3927,  ..., -1.5185, -1.5014, -1.5185],
          [ 1.5639,  1.5810,  1.3755,  ..., -1.5357, -1.5185, -1.5014]],
         [[-0.4076, -0.4601, -0.6527,  ..., -2.0357, -2.0357, -2.0357],
          [-0.4951, -0.5476, -0.5651,  ..., -2.0357, -2.0357, -2.0357],
          [-0.5826, -0.6352, -0.4776,  ..., -2.0357, -2.0357, -2.0357],
          ...,
          [ 1.7283,  1.6232,  1.5532,  ..., -1.4230, -1.4055, -1.4405],
          [ 1.7283,  1.6758,  1.5532,  ..., -1.4230, -1.4055, -1.4230],
          [ 1.7283,  1.7458,  1.5357,  ..., -1.4405, -1.4230, -1.4055]],
         [[-0.1835, -0.2358, -0.4275,  ..., -1.8044, -1.8044, -1.8044],
          [-0.2707, -0.3230, -0.3404,  ..., -1.8044, -1.8044, -1.8044],
          [-0.3578, -0.4101, -0.2532,  ..., -1.8044, -1.8044, -1.8044],
          ...,
          [ 1.9428,  1.8383,  1.7685,  ..., -1.1944, -1.1770, -1.2119],
          [ 1.9428,  1.8905,  1.7685,  ..., -1.1944, -1.1770, -1.1944],
          [ 1.9428,  1.9603,  1.7511,  ..., -1.2119, -1.1944, -1.1770]]],
        [[[-2.0323, -2.0323, -2.0494,  ..., -0.2513, -0.2684, -0.2856],
          [-2.0494, -2.0665, -2.0665,  ...,  0.5364, -0.2684, -0.2513],
          [-2.0665, -2.0665, -2.0665,  ...,  1.1872, -0.2513, -0.2856],
          ...,
          [ 2.1290,  2.0948,  2.0777,  ...,  1.2214,  1.1700,  0.9988],
          [ 2.1804,  2.1633,  2.1119,  ...,  1.2385,  1.1187,  1.1529],
          [ 2.1633,  2.1633,  2.1975,  ...,  1.2043,  1.2557,  1.1358]],
         [[-1.9482, -1.9482, -1.9657,  ..., -0.1275, -0.1450, -0.1625],
          [-1.9657, -1.9832, -1.9832,  ...,  0.6779, -0.1450, -0.1275],
          [-1.9832, -1.9832, -1.9832,  ...,  1.3431, -0.1275, -0.1625],
          ...,
          [ 2.3060,  2.2710,  2.2535,  ...,  1.3782,  1.3256,  1.1506],
          [ 2.3585,  2.3410,  2.2885,  ...,  1.3957,  1.2731,  1.3081],
          [ 2.3410,  2.3410,  2.3761,  ...,  1.3606,  1.4132,  1.2906]],
         [[-1.7173, -1.7173, -1.7347,  ...,  0.0953,  0.0779,  0.0605],
          [-1.7347, -1.7522, -1.7522,  ...,  0.8971,  0.0779,  0.0953],
          [-1.7522, -1.7522, -1.7522,  ...,  1.5594,  0.0953,  0.0605],
          ...,
          [ 2.5180,  2.4831,  2.4657,  ...,  1.5942,  1.5420,  1.3677],
          [ 2.5703,  2.5529,  2.5006,  ...,  1.6117,  1.4897,  1.5245],
          [ 2.5529,  2.5529,  2.5877,  ...,  1.5768,  1.6291,  1.5071]]],
        [[[-1.1247, -1.1247, -1.1418,  ..., -2.0665, -2.0837, -2.1008],
          [-1.1418, -1.1589, -1.1418,  ..., -2.0494, -2.0494, -2.0494],
          [-1.1247, -1.1589, -1.1418,  ..., -2.0494, -2.0494, -2.0665],
          ...,
          [ 2.1804,  2.1804,  2.1975,  ..., -0.5424, -0.7308, -0.9534],
          [ 2.1804,  2.1804,  2.1975,  ..., -0.3712, -0.5082, -0.8507],
          [ 2.2147,  2.2147,  2.2147,  ..., -0.2342, -0.2684, -0.5767]],
         [[-1.0203, -1.0203, -1.0378,  ..., -1.9832, -2.0007, -2.0182],
          [-1.0378, -1.0553, -1.0378,  ..., -1.9657, -1.9657, -1.9657],
          [-1.0203, -1.0553, -1.0378,  ..., -1.9657, -1.9657, -1.9832],
          ...,
          [ 2.3585,  2.3585,  2.3761,  ..., -0.4251, -0.6176, -0.8452],
          [ 2.3585,  2.3585,  2.3761,  ..., -0.2500, -0.3901, -0.7402],
          [ 2.3936,  2.3936,  2.3936,  ..., -0.1099, -0.1450, -0.4601]],
         [[-0.7936, -0.7936, -0.8110,  ..., -1.7522, -1.7696, -1.7870],
          [-0.8110, -0.8284, -0.8110,  ..., -1.7347, -1.7347, -1.7347],
          [-0.7936, -0.8284, -0.8110,  ..., -1.7347, -1.7347, -1.7522],
          ...,
          [ 2.5703,  2.5703,  2.5877,  ..., -0.2010, -0.3927, -0.6193],
          [ 2.5703,  2.5703,  2.5877,  ..., -0.0267, -0.1661, -0.5147],
          [ 2.6051,  2.6051,  2.6051,  ...,  0.1128,  0.0779, -0.2358]]]],
       device='cuda:0')
y: tensor([], device='cuda:0', size=(10, 0))
  0%|                                                             | 0/1000 [00:11<?, ?it/s]
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/mnt/disk1/dungnt-vaipe/federated-learning-dqn/utils/trainer.py", line 40, in train
    _, start_inference_loss = test(model, train_dataloader)
  File "/mnt/disk1/dungnt-vaipe/federated-learning-dqn/utils/trainer.py", line 95, in test
    loss += cel(output, y).item()
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1150, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/site-packages/torch/nn/functional.py", line 2846, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train.py", line 344, in <module>
    main(args)
  File "train.py", line 199, in main
    pool.map(
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: 0D or 1D target tensor expected, multi-target not supported