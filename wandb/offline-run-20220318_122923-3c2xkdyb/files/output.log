>>> START RUNNING: FedAVG-Equal-Non-IID-01-2.1.1 - Train mode: benchmark - Dataset: chexpert
START LOADING CHEXPERT DATASET...
Init State dim 6
Init Action dim 3
ROUND:  0
[5, 5, 5]
output: tensor([[-0.6649, -0.5797],
        [-0.6947, -0.6245],
        [-0.7403, -0.7569],
        [-0.6037, -0.5681],
        [-0.5871, -0.4629],
        [-0.6480, -0.6303],
        [-0.4906, -0.4885],
        [-0.6417, -0.6349],
        [-0.6104, -0.5559],
        [-0.6311, -0.6074]], device='cuda:0', grad_fn=<AddmmBackward0>)
x: tensor([[[[-1.7583, -1.7583, -1.7754,  ..., -1.1760, -1.2445, -1.1760],
          [-1.7412, -1.7412, -1.7412,  ..., -1.1589, -1.1589, -1.2274],
          [-1.6898, -1.6727, -1.6555,  ..., -1.0733, -1.0562, -1.1760],
          ...,
          [-0.1657, -0.0116, -0.0801,  ...,  1.5125,  1.6495,  1.6495],
          [-0.1657,  0.0227, -0.0458,  ...,  1.4440,  1.4954,  1.6495],
          [-0.0801,  0.0056, -0.0116,  ...,  1.2043,  1.3413,  1.4783]],
         [[-1.6681, -1.6681, -1.6856,  ..., -1.0728, -1.1429, -1.0728],
          [-1.6506, -1.6506, -1.6506,  ..., -1.0553, -1.0553, -1.1253],
          [-1.5980, -1.5805, -1.5630,  ..., -0.9678, -0.9503, -1.0728],
          ...,
          [-0.0399,  0.1176,  0.0476,  ...,  1.6758,  1.8158,  1.8158],
          [-0.0399,  0.1527,  0.0826,  ...,  1.6057,  1.6583,  1.8158],
          [ 0.0476,  0.1352,  0.1176,  ...,  1.3606,  1.5007,  1.6408]],
         [[-1.4384, -1.4384, -1.4559,  ..., -0.8458, -0.9156, -0.8458],
          [-1.4210, -1.4210, -1.4210,  ..., -0.8284, -0.8284, -0.8981],
          [-1.3687, -1.3513, -1.3339,  ..., -0.7413, -0.7238, -0.8458],
          ...,
          [ 0.1825,  0.3393,  0.2696,  ...,  1.8905,  2.0300,  2.0300],
          [ 0.1825,  0.3742,  0.3045,  ...,  1.8208,  1.8731,  2.0300],
          [ 0.2696,  0.3568,  0.3393,  ...,  1.5768,  1.7163,  1.8557]]],
        [[[-1.7240, -0.3712,  1.8722,  ..., -1.3302, -1.3644, -1.3302],
          [-0.9363,  1.9578,  2.2147,  ..., -1.3130, -1.3987, -1.4329],
          [-1.6727, -0.2513,  1.8893,  ..., -1.3473, -1.3302, -1.3302],
          ...,
          [ 0.1254,  0.3138,  0.1939,  ...,  1.4269,  1.3413,  1.2214],
          [-0.0287,  0.2282,  0.4337,  ...,  1.2214,  1.2728,  1.1358],
          [-0.0629,  0.2111,  0.3481,  ...,  1.3413,  1.2728,  1.4440]],
         [[-1.6331, -0.2500,  2.0434,  ..., -1.2304, -1.2654, -1.2304],
          [-0.8277,  2.1310,  2.3936,  ..., -1.2129, -1.3004, -1.3354],
          [-1.5805, -0.1275,  2.0609,  ..., -1.2479, -1.2304, -1.2304],
          ...,
          [ 0.2577,  0.4503,  0.3277,  ...,  1.5882,  1.5007,  1.3782],
          [ 0.1001,  0.3627,  0.5728,  ...,  1.3782,  1.4307,  1.2906],
          [ 0.0651,  0.3452,  0.4853,  ...,  1.5007,  1.4307,  1.6057]],
         [[-1.4036, -0.0267,  2.2566,  ..., -1.0027, -1.0376, -1.0027],
          [-0.6018,  2.3437,  2.6051,  ..., -0.9853, -1.0724, -1.1073],
          [-1.3513,  0.0953,  2.2740,  ..., -1.0201, -1.0027, -1.0027],
          ...,
          [ 0.4788,  0.6705,  0.5485,  ...,  1.8034,  1.7163,  1.5942],
          [ 0.3219,  0.5834,  0.7925,  ...,  1.5942,  1.6465,  1.5071],
          [ 0.2871,  0.5659,  0.7054,  ...,  1.7163,  1.6465,  1.8208]]],
        [[[-1.9809, -1.9809, -1.9809,  ..., -1.9809, -1.9980, -1.9980],
          [-1.9809, -1.9809, -1.9809,  ..., -1.9467, -1.9295, -1.9124],
          [-1.9809, -1.9809, -1.9809,  ..., -0.8678, -1.8782, -0.5596],
          ...,
          [-1.8610, -1.8610, -1.8610,  ...,  1.3584,  1.3755,  1.4269],
          [-1.8610, -1.8610, -1.8610,  ...,  1.3070,  1.3070,  1.3755],
          [-1.8610, -1.8610, -1.8610,  ...,  1.2899,  1.2899,  1.3927]],
         [[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.9132, -1.9132],
          [-1.8957, -1.8957, -1.8957,  ..., -1.8606, -1.8431, -1.8256],
          [-1.8957, -1.8957, -1.8957,  ..., -0.7577, -1.7906, -0.4426],
          ...,
          [-1.7731, -1.7731, -1.7731,  ...,  1.5182,  1.5357,  1.5882],
          [-1.7731, -1.7731, -1.7731,  ...,  1.4657,  1.4657,  1.5357],
          [-1.7731, -1.7731, -1.7731,  ...,  1.4482,  1.4482,  1.5532]],
         [[-1.6650, -1.6650, -1.6650,  ..., -1.6650, -1.6824, -1.6824],
          [-1.6650, -1.6650, -1.6650,  ..., -1.6302, -1.6127, -1.5953],
          [-1.6650, -1.6650, -1.6650,  ..., -0.5321, -1.5604, -0.2184],
          ...,
          [-1.5430, -1.5430, -1.5430,  ...,  1.7337,  1.7511,  1.8034],
          [-1.5430, -1.5430, -1.5430,  ...,  1.6814,  1.6814,  1.7511],
          [-1.5430, -1.5430, -1.5430,  ...,  1.6640,  1.6640,  1.7685]]],
        ...,
        [[[-0.9192, -1.1247, -1.2445,  ..., -0.8507, -0.8164, -0.7993],
          [-1.2617, -1.3302, -1.3987,  ..., -0.8164, -0.7822, -0.7822],
          [-1.4843, -1.5185, -1.5357,  ..., -0.7993, -0.7308, -0.6794],
          ...,
          [ 1.0844,  1.0331,  1.0159,  ...,  0.7762,  0.8618,  0.7248],
          [ 0.9132,  0.8618,  0.9646,  ...,  0.8447,  0.8618,  0.7591],
          [ 0.9988,  0.8961,  0.9646,  ...,  0.8789,  0.8104,  0.7591]],
         [[-0.8102, -1.0203, -1.1429,  ..., -0.7402, -0.7052, -0.6877],
          [-1.1604, -1.2304, -1.3004,  ..., -0.7052, -0.6702, -0.6702],
          [-1.3880, -1.4230, -1.4405,  ..., -0.6877, -0.6176, -0.5651],
          ...,
          [ 1.2381,  1.1856,  1.1681,  ...,  0.9230,  1.0105,  0.8704],
          [ 1.0630,  1.0105,  1.1155,  ...,  0.9930,  1.0105,  0.9055],
          [ 1.1506,  1.0455,  1.1155,  ...,  1.0280,  0.9580,  0.9055]],
         [[-0.5844, -0.7936, -0.9156,  ..., -0.5147, -0.4798, -0.4624],
          [-0.9330, -1.0027, -1.0724,  ..., -0.4798, -0.4450, -0.4450],
          [-1.1596, -1.1944, -1.2119,  ..., -0.4624, -0.3927, -0.3404],
          ...,
          [ 1.4548,  1.4025,  1.3851,  ...,  1.1411,  1.2282,  1.0888],
          [ 1.2805,  1.2282,  1.3328,  ...,  1.2108,  1.2282,  1.1237],
          [ 1.3677,  1.2631,  1.3328,  ...,  1.2457,  1.1759,  1.1237]]],
        [[[-0.1828, -0.2684, -0.1657,  ..., -0.7993, -0.6109, -0.4568],
          [-0.1999, -0.0629,  0.0398,  ..., -0.4226, -0.4226, -0.4226],
          [-0.2513,  0.0912,  0.2111,  ..., -0.5082, -0.4911, -0.6281],
          ...,
          [-0.7479, -0.6965, -0.6281,  ...,  0.9646,  0.8961,  0.8961],
          [-0.7479, -0.7650, -0.6452,  ...,  1.0844,  0.9132,  0.8789],
          [-0.8164, -0.8507, -0.6965,  ...,  1.2385,  0.9646,  0.8447]],
         [[-0.0574, -0.1450, -0.0399,  ..., -0.6877, -0.4951, -0.3375],
          [-0.0749,  0.0651,  0.1702,  ..., -0.3025, -0.3025, -0.3025],
          [-0.1275,  0.2227,  0.3452,  ..., -0.3901, -0.3725, -0.5126],
          ...,
          [-0.6352, -0.5826, -0.5126,  ...,  1.1155,  1.0455,  1.0455],
          [-0.6352, -0.6527, -0.5301,  ...,  1.2381,  1.0630,  1.0280],
          [-0.7052, -0.7402, -0.5826,  ...,  1.3957,  1.1155,  0.9930]],
         [[ 0.1651,  0.0779,  0.1825,  ..., -0.4624, -0.2707, -0.1138],
          [ 0.1476,  0.2871,  0.3916,  ..., -0.0790, -0.0790, -0.0790],
          [ 0.0953,  0.4439,  0.5659,  ..., -0.1661, -0.1487, -0.2881],
          ...,
          [-0.4101, -0.3578, -0.2881,  ...,  1.3328,  1.2631,  1.2631],
          [-0.4101, -0.4275, -0.3055,  ...,  1.4548,  1.2805,  1.2457],
          [-0.4798, -0.5147, -0.3578,  ...,  1.6117,  1.3328,  1.2108]]],
        [[[-1.5014, -1.4843, -1.5357,  ..., -1.3130, -1.4329, -1.3815],
          [-1.3302, -1.3644, -1.2959,  ..., -1.7412, -1.6727, -1.7069],
          [-1.2103, -1.2788, -1.1760,  ..., -1.7583, -1.7412, -1.3644],
          ...,
          [ 1.9407,  1.8722,  1.9235,  ..., -1.7240, -1.1932,  1.4440],
          [ 1.9578,  1.9407,  1.9578,  ..., -1.6213, -1.8268,  0.1768],
          [ 2.0092,  1.8722,  1.9235,  ..., -1.6727, -1.8953,  0.5536]],
         [[-1.4055, -1.3880, -1.4405,  ..., -1.2129, -1.3354, -1.2829],
          [-1.2304, -1.2654, -1.1954,  ..., -1.6506, -1.5805, -1.6155],
          [-1.1078, -1.1779, -1.0728,  ..., -1.6681, -1.6506, -1.2654],
          ...,
          [ 2.1134,  2.0434,  2.0959,  ..., -1.6331, -1.0903,  1.6057],
          [ 2.1310,  2.1134,  2.1310,  ..., -1.5280, -1.7381,  0.3102],
          [ 2.1835,  2.0434,  2.0959,  ..., -1.5805, -1.8081,  0.6954]],
         [[-1.1770, -1.1596, -1.2119,  ..., -0.9853, -1.1073, -1.0550],
          [-1.0027, -1.0376, -0.9678,  ..., -1.4210, -1.3513, -1.3861],
          [-0.8807, -0.9504, -0.8458,  ..., -1.4384, -1.4210, -1.0376],
          ...,
          [ 2.3263,  2.2566,  2.3088,  ..., -1.4036, -0.8633,  1.8208],
          [ 2.3437,  2.3263,  2.3437,  ..., -1.2990, -1.5081,  0.5311],
          [ 2.3960,  2.2566,  2.3088,  ..., -1.3513, -1.5779,  0.9145]]]],
       device='cuda:0')
y: tensor([], device='cuda:0', size=(10, 0))
  0%|                                                    | 0/1000 [00:10<?, ?it/s]
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/mnt/disk1/dungnt/federated-learning-dqn/utils/trainer.py", line 40, in train
    _, start_inference_loss = test(model, train_dataloader)
  File "/mnt/disk1/dungnt/federated-learning-dqn/utils/trainer.py", line 95, in test
    loss += cel(output, y).item()
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1150, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/site-packages/torch/nn/functional.py", line 2846, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/mnt/disk1/dungnt/federated-learning-dqn/train.py", line 344, in <module>
    main(args)
  File "/mnt/disk1/dungnt/federated-learning-dqn/train.py", line 199, in main
    pool.map(
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/aiotlab/anaconda3/envs/thanhnt_vaipe/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: 0D or 1D target tensor expected, multi-target not supported