>>> START RUNNING: FedAVG-Equal-Non-IID-01-2.1.1 - Train mode: benchmark - Dataset: chexpert
START LOADING CHEXPERT DATASET...
n_params: 11187158
Init State dim 6
Init Action dim 3
ROUND:  0
[5, 5, 5]
  0%|                                                 | 0/1000 [01:05<?, ?it/s]
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/mnt/disk1/dungnt-vaipe/federated-learning-dqn/utils/trainer.py", line 77, in train
    local_model_weight[id] = flatten_model(local_model)
RuntimeError: The expanded size of the tensor (11187158) must match the existing size (11177538) at non-singleton dimension 0.  Target sizes: [11187158].  Tensor sizes: [11177538]
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train.py", line 345, in <module>
    main(args)
  File "train.py", line 200, in main
    pool.map(
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/aiotlabws/Workspace/Env/anaconda3/envs/longnd/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: The expanded size of the tensor (11187158) must match the existing size (11177538) at non-singleton dimension 0.  Target sizes: [11187158].  Tensor sizes: [11177538]